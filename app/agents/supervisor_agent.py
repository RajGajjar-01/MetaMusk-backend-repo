"""
Supervisor Agent implementation using langchain create_agent.
Coordinates the multi-agent workflow with proper state context injection.
"""
from pathlib import Path
from langchain.agents import create_agent
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.tools import tool
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from typing import Dict
import logging
import json

logger = logging.getLogger(__name__)


def load_prompt(filename: str) -> str:
    """Load prompt from prompts directory"""
    prompt_path = Path(__file__).parent.parent / "prompts" / filename
    return prompt_path.read_text()


# Define routing tools for Supervisor
@tool
def route_to_knowledge(query: str, context: str = "") -> str:
    """
    Route request to Knowledge & Script Agent.
    
    Use this when:
    - User asks for new content
    - Need to research a concept
    - Want script modifications
    - No script_artifacts are available yet
    
    Args:
        query: User's concept request
        context: Additional context or feedback
        
    Returns:
        Routing signal
    """
    logger.info(f"ğŸ”€ Routing to knowledge_agent with query: {query[:100]}...")
    return "knowledge_agent"


@tool
def route_to_execution(reason: str = "Scripts are ready") -> str:
    """
    Route to Execution & Orchestration Agent to render the video.
    
    Use this when:
    - script_artifacts are available and contain valid scenes
    - ScriptPackage has been generated by knowledge_agent
    - Ready to render the animation
    
    Args:
        reason: Reason for routing to execution
        
    Returns:
        Routing signal
    """
    logger.info(f"ğŸ”€ Routing to execution_agent: {reason}")
    return "execution_agent"


@tool
def finish(final_message: str, video_path: str = "") -> str:
    """
    Signal task completion.
    
    Use this when:
    - Final video has been rendered (execution_results contain final_video_path)
    - User's request is complete
    - No further actions needed
    
    Args:
        final_message: Message to user
        video_path: Path to final video
        
    Returns:
        Termination signal
    """
    logger.info(f"âœ… Finishing task: {final_message}")
    return "FINISH"


def create_supervisor_agent():
    """
    Create Supervisor Agent using langchain's create_agent.
    """
    logger.info("ğŸ¯ Creating Supervisor Agent...")
    
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0.2
    )
    
    base_system_prompt = load_prompt("supervisor_agent.txt")
    
    tools = [
        route_to_knowledge,
        route_to_execution,
        finish
    ]
    logger.debug(f"Tools loaded: {[t.name for t in tools]}")
    
    agent = create_agent(
        model=llm,
        tools=tools,
        system_prompt=base_system_prompt
    )
    logger.info("âœ… Supervisor Agent created successfully")
    
    def supervisor_node(state):
        """
        Supervisor node that injects state context into LLM decisions.
        
        This is critical: the LLM needs to know what's available in state
        to make proper routing decisions.
        """
        logger.info("ğŸ¯ Supervisor Agent invoked")
        logger.debug(f"Input state keys: {list(state.keys())}")
        
        # Extract current state
        script_artifacts = state.get("script_artifacts")
        execution_results = state.get("execution_results")
        user_query = state.get("user_query", "")
        
        # Log current state for debugging
        logger.info(f"ğŸ“Š State check:")
        logger.info(f"   - script_artifacts: {'AVAILABLE' if script_artifacts else 'NOT AVAILABLE'}")
        logger.info(f"   - execution_results: {'AVAILABLE' if execution_results else 'NOT AVAILABLE'}")
        
        # CRITICAL FIX: Force finish if we have a valid video path
        if execution_results and isinstance(execution_results, dict):
            video_path = execution_results.get("final_video_path") or execution_results.get("local_path")
            # Check for valid video path (not None, not "None" string, not empty, not mock path without file)
            if video_path and video_path != "None" and video_path != "" and "mock" not in str(video_path).lower():
                logger.info(f"ğŸ¬ Video ready at {video_path}, forcing FINISH")
                return {
                    "messages": [AIMessage(content=f"Video generation complete! Your video is ready at: {video_path}")],
                    "next_action": "FINISH",
                    "current_agent": "supervisor"
                }
            # Also check for completed status with local_path
            if execution_results.get("status") == "completed" and execution_results.get("local_path"):
                local_path = execution_results.get("local_path")
                logger.info(f"ğŸ¬ Video downloaded to {local_path}, forcing FINISH")
                return {
                    "messages": [AIMessage(content=f"Video generation complete! Your video is ready at: {local_path}")],
                    "next_action": "FINISH",
                    "current_agent": "supervisor"
                }
        
        # Build context message to inject into the conversation
        context_parts = []
        context_parts.append(f"[SUPERVISOR STATE UPDATE]")
        context_parts.append(f"User Query: {user_query}")
        
        if script_artifacts:
            # Scripts are ready - should route to execution
            scenes_count = 0
            if isinstance(script_artifacts, dict):
                # Check multiple possible locations for scenes
                if "scenes" in script_artifacts:
                    scenes_count = len(script_artifacts.get("scenes", []))
                elif "video_script" in script_artifacts:
                    scenes_count = len(script_artifacts.get("video_script", {}).get("scenes", []))
                elif "raw_parsed" in script_artifacts:
                    # Check in the raw parsed data
                    raw = script_artifacts.get("raw_parsed", {})
                    if "scenes" in raw:
                        scenes_count = len(raw.get("scenes", []))
                    elif "video_script" in raw:
                        scenes_count = len(raw.get("video_script", {}).get("scenes", []))
                
                logger.debug(f"Script artifacts keys: {list(script_artifacts.keys())}")
            
            context_parts.append(f"âœ… script_artifacts: AVAILABLE ({scenes_count} scenes ready)")
            context_parts.append("ACTION REQUIRED: Call route_to_execution to render the video!")
        else:
            context_parts.append("âŒ script_artifacts: NOT AVAILABLE")
            context_parts.append("ACTION REQUIRED: Call route_to_knowledge to generate scripts first!")
        
        if execution_results:
            video_path = ""
            if isinstance(execution_results, dict):
                video_path = execution_results.get("final_video_path", "")
            context_parts.append(f"âœ… execution_results: AVAILABLE (video: {video_path})")
            context_parts.append("ACTION REQUIRED: Call finish to complete the task!")
        else:
            context_parts.append("âŒ execution_results: NOT AVAILABLE")
        
        context_message = "\n".join(context_parts)
        logger.debug(f"Context message:\n{context_message}")
        
        # Create modified state with context injected
        messages = list(state.get("messages", []))
        messages.append(HumanMessage(content=context_message))
        
        modified_state = {**state, "messages": messages}
        
        try:
            result = agent.invoke(modified_state)
            logger.debug(f"Agent returned with keys: {list(result.keys())}")
            
            next_action = ""
            result_messages = result.get("messages", [])
            logger.debug(f"Message count: {len(result_messages)}")
            
            # Look for tool calls in messages
            for msg in reversed(result_messages):
                if hasattr(msg, "tool_calls") and msg.tool_calls:
                    for tc in msg.tool_calls:
                        tool_name = tc.get("name", "")
                        logger.debug(f"Found tool call: {tool_name}")
                        if tool_name == "route_to_knowledge":
                            next_action = "knowledge_agent"
                            break
                        elif tool_name == "route_to_execution":
                            next_action = "execution_agent"
                            break
                        elif tool_name == "finish":
                            next_action = "FINISH"
                            break
                
                # Also check for direct content matches
                if hasattr(msg, "content") and msg.content in ["knowledge_agent", "execution_agent", "FINISH"]:
                    next_action = msg.content
                    break
                    
                if next_action:
                    break
            
            # FALLBACK LOGIC: If LLM didn't make a decision, use state-based routing
            if not next_action:
                logger.warning("âš ï¸ LLM didn't make a clear routing decision, using state-based fallback")
                if execution_results and execution_results.get("final_video_path"):
                    next_action = "FINISH"
                    logger.info("ğŸ“ Fallback: execution_results has video -> FINISH")
                elif script_artifacts:
                    next_action = "execution_agent"
                    logger.info("ğŸ“ Fallback: script_artifacts ready -> execution_agent")
                else:
                    next_action = "knowledge_agent"
                    logger.info("ğŸ“ Fallback: no artifacts -> knowledge_agent")
            
            # Extract output string
            output_str = ""
            for msg in reversed(result_messages):
                if hasattr(msg, "content") and msg.content and not hasattr(msg, "tool_calls"):
                    output_str = msg.content
                    break
            
            logger.info(f"ğŸ¯ Supervisor decision: next_action={next_action}")
            return {
                "messages": [AIMessage(content=output_str)] if output_str else [],
                "next_action": next_action,
                "current_agent": "supervisor"
            }
        except Exception as e:
            logger.error(f"âŒ Supervisor Agent error: {e}", exc_info=True)
            raise
    
    return supervisor_node


if __name__ == "__main__":
    agent = create_supervisor_agent()
    print("Supervisor Agent created successfully!")
